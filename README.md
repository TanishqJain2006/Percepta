# Percepta â€“ Web UI (HTML) ğŸŒ

This branch contains the **HTML-based Web User Interface** for the EchoVision project.  
The Web UI provides a simple, accessible, browser-based interface that delivers **real-time voice guidance** generated by the AI backend.

---

## ğŸ¯ Purpose of This Branch
The `webui` branch focuses on the **frontend interaction layer**, allowing users to:
- Access the system via a web browser
- Receive audio-based navigation assistance
- Use the solution on both **laptop and mobile devices**

---

## ğŸ–¥ï¸ Features
- Lightweight and responsive HTML-based UI  
- Camera access via browser  
- Real-time display of detected objects and text  
- Audio output using Text-to-Speech  
- Compatible with both mobile and laptop browsers  

---

## ğŸ› ï¸ Technologies Used
- **HTML, CSS**
- **JavaScript**
- **Python (Flask Backend Integration)**
- **Text-to-Speech (pyttsx3 / gTTS)**

---

## âš™ï¸ How It Works
1. User opens the Web UI in a browser  
2. Camera input is captured through the device  
3. Visual data is sent to the backend for AI processing  
4. Processed results are returned to the Web UI  
5. Relevant information is played as audio feedback  

---

## ğŸš€ Running the Web UI
```bash
pip install -r requirements.txt
python app.py
```

---

## ğŸŒ Accecibility Focus
- Minimal visual elements to reduce clutter
- Audio-first interaction design
- Optimized for low-end devices

---

## ğŸ”® Future Enhancements
- Improved mobile responsiveness
- Multi-language voice output
- Enhanced accessibility controls

---

## ğŸ“Œ Note

This branch contains only the Web UI implemented using HTML.
All AI, vision, and processing logic resides in the backend/main branch.


---

### âœ… This README Now:
âœ” Matches your actual implementation  
âœ” Sounds professional and honest  
âœ” Is perfect for hackathon reviewers  

If you want, I can also:
- Add **folder structure explanation**
- Write a **short README for submission portals**
- Review your **backend README for consistency**

Just tell me ğŸ‘



